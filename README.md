# AIÂ Imageâ€‘Gen MCPÂ Server

> **VersionÂ 0.1.0 â€“ first public preview**\
> Conforms to the [ModelÂ ContextÂ ProtocolÂ specÂ (2025â€‘06â€‘18)](https://modelcontextprotocol.io/specification/2025-06-18).

---

## Whatâ€™s this?

A lightweight **MCP server** that turns cuttingâ€‘edge image generators into plugâ€‘andâ€‘play tools for any MCPâ€‘aware client. We start with **GPTâ€‘Imageâ€‘1** from OpenAI; next releases will unlock DALLÂ·E, StableÂ Diffusion and fully local engines â€“ all selectable with a single flag.

### Why MCP?

MCP is the USBâ€‘C of AI context: one cable, endless integrations. Ship one binary, hook it into Claude Desktop, VSÂ Code, or your own chatbot, and the host handles UI, permissions and prompt plumbing.

### Quick examples

| You ask                                                       | The server replies                                          |
| ------------------------------------------------------------- | ----------------------------------------------------------- |
| *â€œGive me a slick hero background for my SaaS landing page.â€* | Delivers a 3840Ã—2160 PNG + CSS gradient vars                |
| *â€œMake that CTA button look like an 18thâ€‘century brick.â€*     | Generates a texture sprite and inline styles ready to paste |

If you can phrase it, the pipeline can render it. ðŸ’«

---

## Core MCP Concepts

This server exposes all three **MCP primitives**:

1. **Tools** â€“ `generate_image`, `upscale_image`, `inpaint_image`
2. **Resources** â€“ generated assets, prompt logs, experiment metadata
3. **Prompts** â€“ reusable templates (e.g. *Product Mockâ€‘up*, *ConceptÂ Art*)

---

## Feature Highlights

- **Model Switcher** â€“ ships with **GPTâ€‘Imageâ€‘1**; upcoming releases add DALLÂ·E, StableÂ Diffusion, and local checkpoints.
- **Prompt Graphs** â€“ YAML pipelines (txt2img â†’ upscale â†’ watermark).
- **Versioned Experiments** â€“ hash promptâ€¯+â€¯seedâ€¯+â€¯params; compare in UI.
- **Async Queue** â€“ Celery/Kafka keeps GPUs busy but not angry.
- **RBAC** â€“ perâ€‘team access so interns canâ€™t torch prod.

---

## Architecture

```mermaid
graph TD
    Host["MCP Client (Claude, IDE, etc.)"] -- JSONâ€‘RPC 2.0 --> Server["Imageâ€‘Gen MCPÂ Server"]
    Server -->|REST / gRPC| Model["GPTâ€‘Imageâ€‘1 (today)\nDALLÂ·E / SD (soon)"]
    Server --> Post[Postâ€‘Processing]
    Post --> Storage[(Object Storage)]
    Storage --> Host
```

---

## Quickstart

### Prerequisites

- **PythonÂ 3.11+**
- **DockerÂ 24+** (GPU containers)
- Optional: **CUDAÂ 12** + nvidiaâ€‘docker for local rendering.

### Installation

```bash
git clone https://github.com/krystian-ai/ai-image-gen-mcp.git
cd ai-image-gen-mcp
python -m venv .venv && source .venv/bin/activate
pip install -e .[image,dev]   # pulls mcp[cli] & diffusers
```

### Configuration

Copy `.env.example` â†’ `.env` and set:

```dotenv
OPENAI_API_KEY=sk-...
MODEL_DEFAULT=gpt-image-1
CACHE_DIR=/path/to/cache
```

### Run (stdio transport)

```bash
mcp-imageserve stdio  # or python -m ai_image_gen_mcp.server --transport=stdio
```

### Connect from Claude Desktop

```jsonc
{
  "mcpServers": {
    "image-gen": {
      "command": "mcp-imageserve",
      "args": ["stdio"],
      "transport": "STDIO"
    }
  }
}
```

Restart Claude âžœ `/image` tool appears.

---

## Roadmap

| Version | Focus                                               | Target Date |
| ------- | --------------------------------------------------- | ----------- |
| **0.1** | Basic functions, GPTâ€‘Imageâ€‘1 support                | 2025â€‘08â€‘31  |
| **0.2** | DALLÂ·E models + modelâ€‘mixing config                 | 2025â€‘09â€‘30  |
| **0.3** | Preâ€‘prompting & style presets for consistent output | 2025â€‘11â€‘30  |
| **0.4** | TBD â€“ communityâ€‘driven features ðŸ¤”                  | 2026â€‘01â€‘30  |

---

## Contributing

Fork â†’ branch â†’ PR. Run `pre-commit` (black, ruff, mypy) before pushing. Document new tools/resources in `docs/`.

---

## License

**ApacheÂ 2.0** â€“ see `LICENSE`.

---

## Links

- **MCP Introduction** â€“ [https://modelcontextprotocol.io/introduction](https://modelcontextprotocol.io/introduction)
- **MCP Quickstart** â€“ [https://modelcontextprotocol.io/quickstart/server](https://modelcontextprotocol.io/quickstart/server)
- **Spec 2025â€‘06â€‘18** â€“ [https://modelcontextprotocol.io/specification/2025-06-18](https://modelcontextprotocol.io/specification/2025-06-18)
- **OpenAI API Docs** â€“ [https://platform.openai.com/docs](https://platform.openai.com/docs)
- **Stable Diffusion Web UI** â€“ [https://github.com/AUTOMATIC1111/stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
- **OpenAI Image Vision API Docs** - [https://platform.openai.com/docs/guides/images-vision?api-mode=responses](https://platform.openai.com/docs/guides/images-vision?api-mode=responses)

